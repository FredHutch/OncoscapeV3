{"method":"Dict Learning Online","desc":"<span class='help-method'>Solves a dictionary learning matrix factorization problem online.</span>Finds the best dictionary and the corresponding sparse code for approximating the data matrix X by solving: (U^*, V^*) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1 (U,V) with || V_k ||_2 = 1 for all  0 <= k < n_components where V is the dictionary and U is the sparse code. This is accomplished by repeatedly iterating over mini-batches by slicing the input data. Read more in the scikit-learn user guide. ","url":"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.dict_learning_online.html","params":[{"name":"X","type":"array of shape (n_samples, n_features)","desc":"Data matrix."},{"name":"n components","type":"int,","desc":"Number of dictionary atoms to extract."},{"name":"alpha","type":"float,","desc":"Sparsity controlling parameter."},{"name":"n iter","type":"int,","desc":"Number of iterations to perform."},{"name":"return code","type":"boolean,","desc":"Whether to also return the code U or just the dictionary V."},{"name":"dict init","type":"array of shape (n_components, n_features),","desc":"Initial value for the dictionary for warm restart scenarios."},{"name":"callback","type":"callable or None, optional (default","desc":"callable that gets invoked every five iterations"},{"name":"batch size","type":"int,","desc":"The number of samples to take in each batch."},{"name":"verbose","type":"bool, optional (default","desc":"To control the verbosity of the procedure."},{"name":"shuffle","type":"boolean,","desc":"Whether to shuffle the data before splitting it in batches."},{"name":"n jobs","type":"int,","desc":"Number of parallel jobs to run, or -1 to autodetect."},{"name":"method","type":"{‘lars’, ‘cd’}","desc":"lars: uses the least angle regression method to solve the lasso problem (linear_model.lars_path) cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). Lars will be faster if the estimated components are sparse."},{"name":"iter offset","type":"int, default 0","desc":"Number of previous iterations completed on the dictionary used for initialization."},{"name":"random state","type":"int, RandomState instance or None, optional (default=None)","desc":"If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random."},{"name":"return inner stats","type":"boolean, optional","desc":"Return the inner statistics A (dictionary covariance) and B (data approximation). Useful to restart the algorithm in an online setting. If return_inner_stats is True, return_code is ignored"},{"name":"inner stats","type":"tuple of (A, B) ndarrays","desc":"Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid loosing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix"},{"name":"return n iter","type":"bool","desc":"Whether or not to return the number of iterations."}],"attrs":[{"name":"code","type":"array of shape (n_samples, n_components),","desc":"the sparse code (only returned if return_code=True)"},{"name":"dictionary","type":"array of shape (n_components, n_features),","desc":"the solutions to the dictionary learning problem"},{"name":"n iter","type":"int","desc":"Number of iterations run. Returned only if return_n_iter is set to True."}]}