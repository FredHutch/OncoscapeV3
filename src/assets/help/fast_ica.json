{
    "method": "Fast ICA",
    "summary": "Is an efficient and popular algorithm for independent component analysis, which is probably the most widely used algorithm for performing independent component analysis, a recently developed variant of factor analysis that is completely estimable unlike classical methods, and able to perform blind source separation",
    "desc": "<span class='help-method'>FastICA: a fast algorithm for Independent Component Analysis.</span> ",
    "url": "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html#sklearn.decomposition.FastICA",
    "params": [
        {
            "name": "n components",
            "type": "int, optional",
            "desc": "Number of components to use. If none is passed, all are used."
        },
        {
            "name": "algorithm",
            "type": "{‘parallel’, ‘deflation’}",
            "desc": "Apply parallel or deflational algorithm for FastICA."
        },
        {
            "name": "whiten",
            "type": "boolean, optional",
            "desc": "If whiten is false, the data is already considered to be whitened, and no whitening is performed."
        },
        {
            "name": "fun",
            "type": "string or function, optional. Default",
            "desc": "The functional form of the G function used in the approximation to neg-entropy. Could be either ‘logcosh’, ‘exp’, or ‘cube’. You can also provide your own function. It should return a tuple containing the value of the function, and of its derivative, in the point. Example:  def my_g(x): return x ** 3, 3 * x ** 2"
        },
        {
            "name": "fun args",
            "type": "dictionary, optional",
            "desc": "Arguments to send to the functional form. If empty and if fun=’logcosh’, fun_args will take value {‘alpha’ : 1.0}."
        },
        {
            "name": "max iter",
            "type": "int, optional",
            "desc": "Maximum number of iterations during fit."
        },
        {
            "name": "tol",
            "type": "float, optional",
            "desc": "Tolerance on update at each iteration."
        },
        {
            "name": "w init",
            "type": "None of an (n_components, n_components) ndarray",
            "desc": "The mixing matrix to be used to initialize the algorithm."
        },
        {
            "name": "random state",
            "type": "int, RandomState instance or None, optional (default=None)",
            "desc": "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random."
        }
    ],
    "attrs": [
        {
            "name": "components",
            "type": "2D array, shape (n_components, n_features)",
            "desc": "The unmixing matrix."
        },
        {
            "name": "mixing",
            "type": "array, shape (n_features, n_components)",
            "desc": "The mixing matrix."
        },
        {
            "name": "n iter",
            "type": "int",
            "desc": "If the algorithm is “deflation”, n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge."
        }
    ],
    "citations": [
        {
            "name": "Scikit-learn: Machine Learning in Python",
            "desc": "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.",
            "url": "http://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf"
        },
        {
            "name": "API design for machine learning software: experiences from the scikit-learn project",
            "desc": "API design for machine learning software: experiences from the scikit-learn project, Buitinck et al., 2013.",
            "url": "http://www.di.ens.fr/sierra/pdfs/icml09.pdf"
        }
    ]
}