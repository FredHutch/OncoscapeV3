{"method":"Spectral Biclustering","desc":"<span class='help-method'>Spectral biclustering (Kluger, 2003).</span>Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure. Read more in the scikit-learn user guide. ","url":"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.bicluster.SpectralBiclustering.html#sklearn.cluster.bicluster.SpectralBiclustering","params":[{"name":"n clusters","type":"integer or tuple (n_row_clusters, n_column_clusters)","desc":"The number of row and column clusters in the checkerboard structure."},{"name":"method","type":"string, optional, default","desc":"Method of normalizing and converting singular vectors into biclusters. May be one of ‘scale’, ‘bistochastic’, or ‘log’. The authors recommend using ‘log’. If the data is sparse, however, log normalization will not work, which is why the default is ‘bistochastic’. CAUTION: if method=’log’, the data must not be sparse."},{"name":"n components","type":"integer, optional, default","desc":"Number of singular vectors to check."},{"name":"n best","type":"integer, optional, default","desc":"Number of best singular vectors to which to project the data for clustering."},{"name":"svd method","type":"string, optional, default","desc":"Selects the algorithm for finding singular vectors. May be ‘randomized’ or ‘arpack’. If ‘randomized’, uses sklearn.utils.extmath.randomized_svd, which may be faster for large matrices. If ‘arpack’, uses scipy.sparse.linalg.svds, which is more accurate, but possibly slower in some cases."},{"name":"n svd vecs","type":"int, optional, default","desc":"Number of vectors to use in calculating the SVD. Corresponds to ncv when svd_method=arpack and n_oversamples when svd_method is ‘randomized`."},{"name":"mini batch","type":"bool, optional, default","desc":"Whether to use mini-batch k-means, which is faster but may get different results."},{"name":"init","type":"{‘k-means++’, ‘random’ or an ndarray}","desc":"Method for initialization of k-means algorithm; defaults to ‘k-means++’."},{"name":"n init","type":"int, optional, default","desc":"Number of random initializations that are tried with the k-means algorithm. If mini-batch k-means is used, the best initialization is chosen and the algorithm runs once. Otherwise, the algorithm is run for each initialization and the best solution chosen."},{"name":"n jobs","type":"int, optional, default","desc":"The number of jobs to use for the computation. This works by breaking down the pairwise matrix into n_jobs even slices and computing them in parallel. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one are used."},{"name":"random state","type":"int, RandomState instance or None, optional, default","desc":"If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random."}],"attrs":[{"name":"rows","type":"array-like, shape (n_row_clusters, n_rows)","desc":"Results of the clustering. rows[i, r] is True if cluster i contains row r. Available only after calling fit."},{"name":"columns","type":"array-like, shape (n_column_clusters, n_columns)","desc":"Results of the clustering, like rows."},{"name":"row labels","type":"array-like, shape (n_rows,)","desc":"Row partition labels."},{"name":"column labels","type":"array-like, shape (n_cols,)","desc":"Column partition labels."}]}